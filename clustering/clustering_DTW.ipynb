{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.preprocessing import TimeSeriesScalerMeanVariance\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (15424, 18)\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing the CSV files\n",
    "path = \"data/data_ilr_transformed/\"\n",
    "\n",
    "# Generate a list of file paths for the long datasets\n",
    "file_list = [f\"{path}d_study{i}_long.csv\" for i in range(1, 9)]\n",
    "\n",
    "# Read and combine all datasets into one DataFrame\n",
    "df = pd.concat([pd.read_csv(file) for file in file_list], ignore_index=True)\n",
    "\n",
    "# Check the resulting combined DataFrame\n",
    "print(f\"Combined dataset shape: {df.shape}\")\n",
    "\n",
    "# Variable lists\n",
    "ilr_columns = ['ilr1', 'ilr2', 'ilr3']\n",
    "control_columns = ['excluded', 'injustice', 'personal', 'violence']\n",
    "\n",
    "# Eliminating NAs\n",
    "df = df[df['gender'].notna()]\n",
    "df = df[df['age'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  5,  6,  7,  9, 10, 11, 13, 14, 15])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['time'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating -1 and -2 lag features for each ilr variable\n",
    "for col in ilr_columns:\n",
    "    df[f'{col}_lag1'] = df.groupby('ID')[col].shift(1)\n",
    "    df[f'{col}_lag2'] = df.groupby('ID')[col].shift(2)\n",
    "\n",
    "# Calculate mean and standard deviation per participant (ID) for each ilr column\n",
    "for col in ilr_columns:\n",
    "    # Mean per participant\n",
    "    df[f'{col}_mean'] = df.groupby('ID')[col].transform('mean')\n",
    "    \n",
    "    # Standard deviation per participant\n",
    "    df[f'{col}_std'] = df.groupby('ID')[col].transform('std')\n",
    "    \n",
    "    # Minimum and maximum values per participant\n",
    "    df[f'{col}_min'] = df.groupby('ID')[col].transform('min')\n",
    "    df[f'{col}_max'] = df.groupby('ID')[col].transform('max')\n",
    "\n",
    "\n",
    "# Additional time-based feature: time point relative to the total duration for each participant\n",
    "# This provides a scaled measure of progression within the time series\n",
    "df['relative_time'] = df.groupby('ID')['time'].transform(lambda x: x / x.max())\n",
    "\n",
    "\n",
    "# Optional cumulative feature: cumulative sum of the 'ilr' values within each participant's time series\n",
    "# This can capture a trend or overall trajectory for each ilr over time\n",
    "#for col in ilr_columns:\n",
    "#    df[f'{col}_cumsum'] = df.groupby('ID')[col].cumsum()\n",
    "\n",
    "\n",
    "## Response Variability Over Time:\n",
    "#for col in ilr_columns:\n",
    "#    df[f'{col}_delta'] = df.groupby('ID')[col].diff().fillna(0)  # Absolute change from previous time point\n",
    "\n",
    "\n",
    "## Interaction Terms: Control Variables with Time\n",
    "#for col in control_columns:\n",
    "#    df[f'{col}_time_interaction'] = df[col] * df['time']\n",
    "\n",
    "\n",
    "# Calculate deviation from the mean of each ilr value within each experiment and time point\n",
    "#for col in ilr_columns:\n",
    "#    df[f'{col}_deviation_from_group'] = df[col] - df.groupby(['Experiment', 'time'])[col].transform('mean')\n",
    "\n",
    "\n",
    "# Calculate the trend/slope for each ilr column\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#for col in ilr_columns:\n",
    "#    df[f'{col}_trend'] = df.groupby('ID').apply(lambda x: \n",
    "#        LinearRegression().fit(x[['time']], x[col]).coef_[0] if len(x) > 1 else np.nan).reset_index(level=0, drop=True)\n",
    "\n",
    "\n",
    "# Moving Average or Exponential Moving Average (EMA)\n",
    "window_size = 3  # Define your preferred window size\n",
    "for col in ilr_columns:\n",
    "    df[f'{col}_moving_avg'] = df.groupby('ID')[col].transform(lambda x: x.rolling(window=window_size, min_periods=1).mean())\n",
    "    # df[f'{col}_ema'] = df.groupby('ID')[col].transform(lambda x: x.ewm(span=window_size, adjust=False).mean())\n",
    "\n",
    "\n",
    "\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "\n",
    "# List of ilr columns\n",
    "ilr_columns = ['ilr1', 'ilr2', 'ilr3']\n",
    "ilr_moving_avg_cols = ['ilr1_moving_avg', 'ilr2_moving_avg', 'ilr3_moving_avg']\n",
    "\n",
    "# Residualize each ilr variable\n",
    "for col in ilr_moving_avg_cols:\n",
    "    # Fit the mixed-effects model\n",
    "    model = MixedLM.from_formula(f\"{col} ~ relative_time\", groups=\"Experiment\", data=df)\n",
    "    result = model.fit()\n",
    "    \n",
    "    # Add residuals to the DataFrame\n",
    "    df[f'{col}_residual'] = df[col] - result.fittedvalues\n",
    "\n",
    "ilr_resid_columns = ['ilr1_residual', 'ilr2_residual', 'ilr3_residual']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Number of Fourier components to retain\n",
    "fourier_components = 1\n",
    "\n",
    "ilr_moving_avg_residual_cols = ['ilr1_moving_avg_residual', 'ilr2_moving_avg_residual', 'ilr3_moving_avg_residual']\n",
    "\n",
    "# Compute Fourier transform for each 'ilr' variable per participant\n",
    "for col in ilr_moving_avg_residual_cols:\n",
    "    def compute_fourier(x):\n",
    "        fft_vals = np.fft.fft(x)\n",
    "        # Retain only the first N components (real and imaginary parts)\n",
    "        return np.hstack([fft_vals.real[:fourier_components], fft_vals.imag[:fourier_components]])\n",
    "\n",
    "    # Apply Fourier transformation and store as separate columns\n",
    "    fourier_df = (\n",
    "        df.groupby('ID')[col]\n",
    "        .apply(lambda x: compute_fourier(x.values))\n",
    "        .apply(pd.Series)\n",
    "        .rename(columns=lambda i: f'{col}_fourier_{i+1}')\n",
    "    )\n",
    "\n",
    "    # Add Fourier features back to the dataframe\n",
    "    df = df.join(fourier_df, on='ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare Time Series Data for Clustering\n",
    "# Collect each participantâ€™s data with the new features into a standardized time series format\n",
    "\n",
    "time_series_data = []\n",
    "grouped = df.groupby(\"ID\")\n",
    "\n",
    "# Define the feature columns to include in time series\n",
    "feature_columns = [\n",
    "    # 'condition', \n",
    "    'gender', 'age',\n",
    "    #'ilr1', 'ilr2', 'ilr3', \n",
    "    'excluded', 'injustice', 'personal', 'violence',\n",
    "    #'ilr1_lag1', 'ilr2_lag1', 'ilr3_lag1', 'ilr1_lag2', 'ilr2_lag2', 'ilr3_lag2',\n",
    "    #'ilr1_mean', 'ilr2_mean', 'ilr3_mean', 'ilr1_std', 'ilr2_std', 'ilr3_std',\n",
    "    #'ilr1_min', 'ilr2_min', 'ilr3_min', 'ilr1_max', 'ilr2_max', 'ilr3_max',\n",
    "    'relative_time', \n",
    "    ######'ilr1_cumsum', 'ilr2_cumsum', 'ilr3_cumsum', \n",
    "    ######'ilr1_delta', 'ilr2_delta', 'ilr3_delta',  ### definitely nono\n",
    "    #'excluded_time_interaction', 'injustice_time_interaction', 'personal_time_interaction', 'violence_time_interaction',\n",
    "    #'ilr1_deviation_from_group', 'ilr2_deviation_from_group', 'ilr3_deviation_from_group',\n",
    "    #'ilr1_trend', 'ilr2_trend', 'ilr3_trend', \n",
    "    # 'ilr1_moving_avg', 'ilr2_moving_avg', 'ilr3_moving_avg', \n",
    "    ######'ilr1_ema', 'ilr2_ema', 'ilr3_ema',\n",
    "    #'ilr1_residual', 'ilr2_residual', 'ilr3_residual',\n",
    "    #'ilr1_fourier_1', 'ilr2_fourier_1', 'ilr3_fourier_1',\n",
    "    #'ilr1_fourier_2', 'ilr2_fourier_2', 'ilr3_fourier_2'\n",
    "    # 'ilr1_moving_avg_fourier_1', 'ilr2_moving_avg_fourier_2', 'ilr3_moving_avg_fourier_1',\n",
    "    'ilr1_moving_avg_residual_fourier_1',\n",
    "    #'ilr1_moving_avg_residual_fourier_2',\n",
    "    'ilr2_moving_avg_residual_fourier_1',\n",
    "    #'ilr2_moving_avg_residual_fourier_2',\n",
    "    'ilr3_moving_avg_residual_fourier_1',\n",
    "    #'ilr3_moving_avg_residual_fourier_2'\n",
    "\n",
    "]\n",
    "\n",
    "# Preprocess the time series data for each participant\n",
    "for participant, group in grouped:\n",
    "    group_sorted = group.sort_values(\"time\")\n",
    "    time_series = group_sorted[feature_columns].values\n",
    "    \n",
    "    # Pad or truncate each participant's time series to the same length\n",
    "    max_length = 16  # Adjust as necessary\n",
    "    if len(time_series) < max_length:\n",
    "        time_series = np.pad(time_series, ((0, max_length - len(time_series)), (0, 0)), 'constant', constant_values=np.nan)\n",
    "    else:\n",
    "        time_series = time_series[:max_length]\n",
    "    \n",
    "    time_series_data.append(time_series)\n",
    "\n",
    "# Convert to numpy array for clustering\n",
    "time_series_data = np.array(time_series_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
