---
title: "Radicalization Lab"
subtitle: "Code sheet 3: Combining datasets"
author: "Arda Ergin"
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
---

# Setup
IMPORTANT FOR THE USER OF THIS SCRIPT: you have to load the R package "**RadLab**". This is necessary for the code to work properly. See [the GitHub repository](https://github.com/ardaergin/RadLab) for further information.           

The code below loads the RadLab package, you need to download the "devtools" package first, you can do so with install.packages("devtools").
```{r, message=FALSE, warning=FALSE}
# First install the package with: 
devtools::install_github("ardaergin/RadLab")
library(RadLab)
library(dplyr)
library(ggplot2)
library(stats)
library(lme4)
library(lmerTest)
library(optimx)
library(readxl)

library(MCMCglmm)
library(compositions)
library(zCompositions)
```


```{r}
load("data_working/d_combined.Rdata")

df_ilr <- RadLab::prepare_compositional_data(data_combined)

df_ilr_export <- df_ilr %>% select(
  time, 
  ID, 
  Experiment, 
  excluded, injustice, personal, violence,
  ilr1, ilr2, ilr3)

write.csv(df_ilr_export, file = "data_working/ilr_transformed_full_data.csv", row.names = FALSE)
```








```{r}
library(blavaan)

# Define the model with random intercepts for Experiment and random slopes for time by ID
model <- '
  # Latent variable representing radicalization
  radicalization =~ ilr1 + ilr2 + ilr3
  
  # Dynamic time-lagged effect
  radicalization ~ lag(radicalization, -1)
  
  # Control variables as predictors
  radicalization ~ excluded + injustice + personal + violence
  
  # Random intercept for Experiment
  radicalization ~ Experiment
  
  # Random slope for time within each participant (ID)
  radicalization ~ time | ID
'
# Fit the model
fit <- blavaan::blavaan(model, data = data_combined, auto.fix.first = TRUE)
summary(fit)


```

```{r}
data_combined <- data_combined[order(data_combined$ID, data_combined$time), ]

library(tsibble)

# Convert data to a tsibble, indexing by `time` for each `ID`
data_ts <- df_ilr %>%
  as_tsibble(index = time, key = ID)

# Create lagged variables using tsibble
data_ts <- data_ts %>%
  dplyr::mutate(
    ilr1_lag1 = dplyr::lag(ilr1, n = 1, order_by = time),
    ilr2_lag1 = dplyr::lag(ilr2, n = 1, order_by = time),
    ilr3_lag1 = dplyr::lag(ilr3, n = 1, order_by = time)
  )


library(dsem)

# Specify the DSEM model syntax
sem_model <- "
   # Define the latent variable with lagged autoregression
   radicalization =~ ilr1 + ilr2 + ilr3
   radicalization ~ lag(radicalization, 1)

   # Include control variables as predictors
   radicalization ~ excluded + injustice + personal + violence

   # Random intercept for Experiment
   radicalization ~ Experiment

   # Random slope for time within each participant (ID)
   radicalization ~ (1 + time | ID)
"

# Fit the model
fit <- dsem::dsem(
    sem = sem_model,
    tsdata = data_ts,  # Ensure your data is structured as a time series object
    estimate_delta0 = TRUE,
    control = dsem_control(quiet = FALSE)
)

summary(fit)

```



```{r}
model <- lm(cbind(ilr1, ilr2, ilr3) ~ time + excluded + injustice + personal + violence + condition_f, data = df_ilr)
summary(model)

library(lme4)
model <- lmer(cbind(ilr1, ilr2, ilr3) ~ time + 
                excluded + injustice + personal + violence + 
                condition_f + 
                (1 | ID), data = df_ilr)
summary(model)

model_manova <- manova(cbind(ilr1, ilr2, ilr3) ~ time + 
                         excluded + injustice + personal + violence + 
                         condition_f, data = df_ilr)
summary(model_manova)

library(brms)
model_brms <- brm(
  bf(ilr1 ~ time + excluded + injustice + personal + violence + condition_f + (1 | ID)) +
  bf(ilr2 ~ time + excluded + injustice + personal + violence + condition_f + (1 | ID)) +
  bf(ilr3 ~ time + excluded + injustice + personal + violence + condition_f + (1 | ID)),
  data = df_ilr,
  chains = 4, cores = 4
)
```

```{r}
# Extract residuals
residuals <- residuals(model)

# Q-Q plot for normality
qqnorm(residuals)
qqline(residuals, col = "red")

# Shapiro-Wilk test for normality
shapiro.test(residuals)

```



# Data preparation

```{r}
df <- data %>%
  dplyr::mutate(
    inaction_prop = ina / 100,
    normative_prop = na / 100,
    nonnormative_prop = nna / 100,
    extreme_nonnormative_prop = enna / 100
  )
```

```{r}
# Create a matrix of the compositional data
comp_matrix <- as.matrix(
  df[, c('inaction_prop', 
         'normative_prop', 
         'nonnormative_prop', 
         'extreme_nonnormative_prop')])
```

```{r}
# Use zPatterns to see the pattern of zeros
zCompositions::zPatterns(comp_matrix, label = 0)

# Check for NA values in comp_matrix
sum(is.na(comp_matrix))

?cmultRepl
```

```{r}
# Replace zeros using the multiplicative replacement method
comp_matrix_nozeros <- cmultRepl(
  comp_matrix,
  method = "CZM",
  output = "prop",
  label = 0,
  z.delete = FALSE # Prevent deletion of columns/rows
)
```



```{r}
# Create acomp object with labels
comp_data <- acomp(comp_matrix_nozeros)

# Perform ilr transformation
## ilr_data will have D - 1 columns, where D is the number of components (4 in your case)
ilr_data <- ilr(comp_data)

# Convert ilr_data to a data frame and name the columns
ilr_df <- as.data.frame(ilr_data)
colnames(ilr_df) <- c('ilr1', 'ilr2', 'ilr3')

# Combine with your original data
df_ilr <- cbind(df, ilr_df)
```


```{r}
library(mlVAR)

variables_network <- c("mood", "arousal", "valence", "activity", "call", "sms", "appCat.builtin", "appCat.communication", "appCat.entertainment", "appCat.finance", "appCat.game", "appCat.office", "appCat.other", "appCat.social",)


ml_mod <- mlVAR::mlVAR(
  data = df_ilr, 
  vars = c("ilr1", "ilr2", "ilr3", 
           "excluded", "injustice", "personal", "violence", "condition_f"), 
  idvar = "ID",
  timevar="time",
  estimator = "lmer", 
  temporal = "correlated", 
  contemporaneous = "correlated"
)




```





# Modelling

```{r}
prior <- list(R = list(V = diag(3), nu = 0.002),  # rcov prior
              G = list(G1 = list(V = diag(3), nu = 10),  # stronger prior for ID
                       G2 = list(V = diag(3), nu = 10)))  # stronger prior for ID:time

mcmc_model <- MCMCglmm::MCMCglmm(
  cbind(ilr1, ilr2, ilr3) ~ trait:(time + excluded + injustice + personal + violence + condition_f) - 1,
  random = ~ us(trait):ID + idh(trait):ID:time,
  rcov = ~ us(trait):units,
  family = rep("gaussian", 3),
  data = df_ilr,
  prior = prior,
  verbose = FALSE
)

save(mcmc_model, file = "data_working/study_2_result.Rdata")

summary(mcmc_model)
```

```{r}
# Extract fixed effects estimates
fixed_effects <- mcmc_model$Sol[, grep("trait", colnames(mcmc_model$Sol))]

# Calculate posterior means
mean_effects <- apply(fixed_effects, 2, mean)

# Create a matrix for ilr coordinates
ilr_pred <- matrix(mean_effects, ncol = 2)

# Back-transform to compositions
comp_pred <- compositions::ilrInv(ilr_pred, orig = comp_data)

# Convert to data frame and name columns
comp_pred_df <- as.data.frame(comp_pred)
colnames(comp_pred_df) <- c('normative_prop', 'nonnormative_prop', 'extreme_nonnormative_prop')

# Now you can interpret or plot comp_pred_df

```




```{r}
library(compositions)
library(cluster)
library(factoextra)

# Prepare data
comp_data <- acomp(your_compositional_data)
ilr_data <- ilr(comp_data)

# Summarize trajectories
# Compute mean ilr values for each participant
ilr_means <- aggregate(ilr_data, by = list(ParticipantID), FUN = mean)

# Clustering
set.seed(123)
kmeans_result <- kmeans(ilr_means[, -1], centers = 3)  # Adjust centers as needed

# Visualization
fviz_cluster(kmeans_result, data = ilr_means[, -1])

```
 







